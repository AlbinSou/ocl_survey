{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import jsonlines\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.toolkit.process_results import extract_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580f5b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes = extract_results(\"/DATA/ocl_survey/er_split_cifar100_20_2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cada13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continual = dataframes[\"continual\"]\n",
    "df_training = dataframes[\"training\"]\n",
    "df_probing = dataframes[\"probing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb629fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_training[\"Top1_Acc_Stream/eval_phase/test_stream/Task000\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cc9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the test accuracy curves, one point after each experience\n",
    "# the frame is reindexed so that it can match the curve of probing\n",
    "\n",
    "final_test_acc = df_training.groupby(\"mb_index\").agg([\"mean\", \"std\"])[\"Top1_Acc_Stream/eval_phase/test_stream/Task000\"]\n",
    "final_test_acc[\"training_task\"] = final_test_acc.index.argsort()\n",
    "final_test_acc = final_test_acc.fillna(0)\n",
    "\n",
    "final_probing = df_probing.groupby(\"mb_index\").agg([\"mean\", \"std\"])[\"Top1_Acc_Stream/eval_phase/test_stream/Task000\"]\n",
    "final_probing[\"training_task\"] = final_probing.index.argsort()\n",
    "final_probing = final_probing.fillna(0)\n",
    "\n",
    "sns.lineplot(data=final_probing, x=\"training_task\", y=\"mean\", label=\"ER (Probed)\")\n",
    "\n",
    "plt.fill_between(final_probing['training_task'], final_probing['mean'] - final_probing['std'], final_probing['mean'] + final_probing['std'], alpha=0.2)\n",
    "\n",
    "sns.lineplot(data=final_test_acc, x=\"training_task\", y=\"mean\", label=\"ER\")\n",
    "\n",
    "plt.fill_between(final_test_acc['training_task'], final_test_acc['mean'] - final_test_acc['std'], final_test_acc['mean'] + final_test_acc['std'], alpha=0.2)\n",
    "\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.xlabel(\"Training Task\")\n",
    "plt.grid()\n",
    "plt.ylim(0.1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(data=df_training, x=\"mb_index\", y=\"Top1_Acc_Stream/eval_phase/test_stream/Task000\", errorbar=\"sd\")\n",
    "sns.lineplot(data=df_probing, x=\"mb_index\", y=\"Top1_Acc_Stream/eval_phase/test_stream/Task000\", errorbar=\"sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e9588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
