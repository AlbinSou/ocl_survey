{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eaa110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.toolkit.process_results import extract_results\n",
    "from src.toolkit.post_metrics import compute_forgetting, compute_average, compute_average_forgetting, compute_AAA, compute_mean_std_metric, compute_wcacc, decorate_with_training_task\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.style.use(\"matplotlibrc.template\")\n",
    "colors = plt.cm.Dark2.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_dict(benchmark, memory_size, include_gdumb=False):\n",
    "    results_dict = {\"ER\": f\"er_{benchmark}_20_{memory_size}\", \n",
    "                \"$\\operatorname{ER-ACE}$\":  f\"er_ace_{benchmark}_20_{memory_size}\",\n",
    "                \"DER++\":  f\"der_{benchmark}_20_{memory_size}\",\n",
    "                \"MIR\":  f\"mir_{benchmark}_20_{memory_size}\",\n",
    "                \"ER + LwF\":  f\"er_lwf_{benchmark}_20_{memory_size}\",\n",
    "                #\"AGEM\":  f\"agem_{benchmark}_20_{memory_size}\",\n",
    "                \"RAR\":  f\"rar_{benchmark}_20_{memory_size}\",\n",
    "                \"SCR\":  f\"scr_{benchmark}_20_{memory_size}\",\n",
    "                \"i.i.d\":  f\"er_{benchmark}_1_{memory_size}\",\n",
    "                }\n",
    "    \n",
    "    if include_gdumb:\n",
    "        results_dict[\"GDumb\"] = f\"gdumb_{benchmark}_20_{memory_size}\"\n",
    "        \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"ENTER RESULTS PATH HERE\"\n",
    "memory_size = 2000\n",
    "benchmark = \"split_cifar100\"\n",
    "results_dict = {\"ER\": f\"er_{benchmark}_20_{memory_size}\", \n",
    "                \"$\\operatorname{ER-ACE}$\":  f\"er_ace_{benchmark}_20_{memory_size}\",\n",
    "                \"DER++\":  f\"der_{benchmark}_20_{memory_size}\",\n",
    "                \"MIR\":  f\"mir_{benchmark}_20_{memory_size}\",\n",
    "                \"ER + LwF\":  f\"er_lwf_{benchmark}_20_{memory_size}\",\n",
    "                #\"AGEM\":  f\"agem_{benchmark}_20_{memory_size}\",\n",
    "                \"RAR\":  f\"rar_{benchmark}_20_{memory_size}\",\n",
    "                \"SCR\":  f\"scr_{benchmark}_20_{memory_size}\",\n",
    "                #\"GDumb\":  f\"gdumb_{benchmark}_20_{memory_size}\",\n",
    "                \"i.i.d\":  f\"er_{benchmark}_1_{memory_size}\",\n",
    "                }\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d788ee",
   "metadata": {},
   "source": [
    "# Adjusted Acc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c974f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "for i, (method_label, method_path) in enumerate(results_dict.items()):\n",
    "    frames_method = extract_results(os.path.join(results_path, method_path))\n",
    "    df = frames_method[\"continual\"]\n",
    "    if method_label != \"i.i.d\":\n",
    "        metric_list = [\n",
    "            f\"Top1_Acc_Exp/eval_phase/valid_stream/Task000/Exp{i:03d}\"\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        df[\"training_exp\"] = df[metric_list].count(axis=1)\n",
    "        df[\"StreamAcc\"] = (\n",
    "            df[\"Top1_Acc_Stream/eval_phase/valid_stream/Task000\"]\n",
    "            * df[\"training_exp\"]\n",
    "            / 20\n",
    "        )\n",
    "    else:\n",
    "        df[\"StreamAcc\"] = df[\"Top1_Acc_Stream/eval_phase/valid_stream/Task000\"]\n",
    "\n",
    "    df[\"smoothed_StreamAcc\"] = (\n",
    "        df.groupby(\"seed\")[\"StreamAcc\"]\n",
    "        .rolling(10, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"mb_index\", y=\"smoothed_StreamAcc\", errorbar=\"sd\", color=colors[i]\n",
    "    )\n",
    "    \n",
    "plt.xlabel(\"Batch index\")\n",
    "plt.ylabel(\"Stream Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7e422",
   "metadata": {},
   "source": [
    "# Forgetting Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e156e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forgetting (on normal stream)\n",
    "\n",
    "for i, (method_label, method_path) in enumerate(results_dict.items()):\n",
    "    if method_label == \"i.i.d\": continue\n",
    "    \n",
    "    frames = extract_results(os.path.join(results_path, method_path))\n",
    "    \n",
    "    df = compute_average_forgetting(\n",
    "        frames[\"training\"],\n",
    "        20,\n",
    "        base_name=\"Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp\")\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"training_exp\",\n",
    "        y=\"Average_Forgetting\",\n",
    "        errorbar=None,\n",
    "        label=method_label,\n",
    "        color=colors[i])\n",
    "    \n",
    "    df = compute_average_forgetting(\n",
    "        frames[\"training\"],\n",
    "        20,\n",
    "        base_name=\"CumulativeAccuracy/eval_phase/test_stream/Exp\",\n",
    "        name=\"Average_Cumulative_Forgetting\")\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"training_exp\",\n",
    "        y=\"Average_Cumulative_Forgetting\",\n",
    "        errorbar=None,\n",
    "        color=colors[i],\n",
    "        linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Training task\")\n",
    "plt.ylabel(\"Forgetting\")\n",
    "plt.gca().set_xticks(list(range(1, 21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc47c17",
   "metadata": {},
   "source": [
    "# Task shift figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (method_label, method_path) in enumerate(results_dict.items()):\n",
    "    if method_label not in [\"ER\", \"SCR\"]: continue\n",
    "    \n",
    "    frames = extract_results(os.path.join(results_path, method_path))\n",
    "    \n",
    "    df = frames[\"continual\"]\n",
    "    step1 = 238*4\n",
    "    df = df[(df.mb_index > step1 - 238//2) & (df.mb_index < step1 + 238//2)]\n",
    "    \n",
    "    key1 = \"Top1_Acc_Exp/eval_phase/valid_stream/Task000/Exp003\"\n",
    "    key2 = \"Top1_Acc_Exp/eval_phase/valid_stream/Task000/Exp004\"\n",
    "    \n",
    "    df[f\"smoothed_{key1}\"] = (\n",
    "        df.groupby(\"seed\")[key1]\n",
    "        .rolling(10, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "       \n",
    "    df[f\"smoothed_{key2}\"] = (\n",
    "        df.groupby(\"seed\")[key2]\n",
    "        .rolling(10, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "    sns.lineplot(data=df, x=\"mb_index\", y=f\"smoothed_{key1}\", label=method_label, color=colors[i], linestyle=\"--\")\n",
    "    sns.lineplot(data=df, x=\"mb_index\", y=f\"smoothed_{key2}\", color=colors[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "plt.xlabel(\"Batch index\")\n",
    "plt.ylabel(\"Task accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ed3b3",
   "metadata": {},
   "source": [
    "# Cumulative Accuracy figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (method_label, method_path) in enumerate(results_dict.items()):\n",
    "    if method_label not in [\"ER\", \"SCR\"]: continue\n",
    "    \n",
    "    frames = extract_results(os.path.join(results_path, method_path))\n",
    "    \n",
    "    df = frames[\"continual\"]\n",
    "    \n",
    "    key = \"CumulativeAccuracy/eval_phase/valid_stream/Exp010\"\n",
    "    \n",
    "    df[f\"smoothed_{key}\"] = (\n",
    "        df.groupby(\"seed\")[key]\n",
    "        .rolling(10, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "   \n",
    "    sns.lineplot(data=df, x=\"mb_index\", y=f\"smoothed_{key}\", label=method_label, color=colors[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953722ac",
   "metadata": {},
   "source": [
    "# Multiple memory sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58df106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "filtered_methods = [\"ER\", \"i.i.d\", \"GDumb\"]\n",
    "\n",
    "# means : {\"method-name\": [mean_mem_1, mean_mem_2, ...]}\n",
    "means, stds = defaultdict(list), defaultdict(list)\n",
    "\n",
    "memory_sizes = [500, 2000, 8000]\n",
    "\n",
    "for memory_size in memory_sizes:\n",
    "    results_dict = create_results_dict(benchmark, memory_size, include_gdumb=True)\n",
    "    for method in filtered_methods:\n",
    "        frame = extract_results(os.path.join(results_path, results_dict[method]))[\"training\"]\n",
    "        mean, std = compute_mean_std_metric(frame, \"Top1_Acc_Stream/eval_phase/test_stream/Task000\")\n",
    "        means[method].append(mean)\n",
    "        stds[method].append(std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ecc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(x=memory_sizes, y=means[\"ER\"])\n",
    "method_colors = {\"ER\": 0, \"i.i.d\": 7, \"GDumb\": 5}\n",
    "\n",
    "for method in filtered_methods:\n",
    "    plt.errorbar(x=memory_sizes, y=means[method], yerr=stds[method], color=colors[method_colors[method]], label=method)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Memory size\")\n",
    "plt.ylabel(\"Final Accuracy\")\n",
    "plt.gca().set_xticks(memory_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63dddd",
   "metadata": {},
   "source": [
    "# Joined Adjusted Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = create_results_dict(\"split_cifar100\", 2000)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "for i, (method_label, method_path) in enumerate(results_dict.items()):\n",
    "    frames_method = extract_results(os.path.join(results_path, method_path))\n",
    "    df = frames_method[\"continual\"]\n",
    "    if method_label != \"i.i.d\":\n",
    "        metric_list = [\n",
    "            f\"Top1_Acc_Exp/eval_phase/valid_stream/Task000/Exp{i:03d}\"\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        df[\"training_exp\"] = df[metric_list].count(axis=1)\n",
    "        df[\"StreamAcc\"] = (\n",
    "            df[\"Top1_Acc_Stream/eval_phase/valid_stream/Task000\"]\n",
    "            * df[\"training_exp\"]\n",
    "            / 20\n",
    "        )\n",
    "    else:\n",
    "        df[\"StreamAcc\"] = df[\"Top1_Acc_Stream/eval_phase/valid_stream/Task000\"]\n",
    "\n",
    "    df[\"smoothed_StreamAcc\"] = (\n",
    "        df.groupby(\"seed\")[\"StreamAcc\"]\n",
    "        .rolling(10, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    # Check\n",
    "    # print(df[df.seed==0][\"smoothed_StreamAcc\"])\n",
    "    # print(df[df.seed==0][\"StreamAcc\"])\n",
    "    #sns.lineplot(\n",
    "    #    data=df, x=\"mb_index\", y=\"smoothed_StreamAcc\", errorbar=\"sd\", label=method_label, color=colors[i]\n",
    "    #)\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"mb_index\", y=\"smoothed_StreamAcc\", errorbar=\"sd\", color=colors[i], ax=axes[0]\n",
    "    )\n",
    "\n",
    "axes[0].set_xlabel(\"Batch index\")\n",
    "axes[0].set_ylabel(\"Stream Accuracy\")\n",
    "    \n",
    "results_dict = create_results_dict(\"split_tinyimagenet\", 4000)\n",
    "results_path = \"/DATA/ocl_survey/results_server/\"\n",
    "    \n",
    "for i, (method_label, method_path) in enumerate(results_dict.items()):\n",
    "    frames_method = extract_results(os.path.join(results_path, method_path))\n",
    "    df = frames_method[\"continual\"]\n",
    "    if method_label != \"i.i.d\":\n",
    "        metric_list = [\n",
    "            f\"Top1_Acc_Exp/eval_phase/valid_stream/Task000/Exp{i:03d}\"\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        df[\"training_exp\"] = df[metric_list].count(axis=1)\n",
    "        df[\"StreamAcc\"] = (\n",
    "            df[\"Top1_Acc_Stream/eval_phase/valid_stream/Task000\"]\n",
    "            * df[\"training_exp\"]\n",
    "            / 20\n",
    "        )\n",
    "    else:\n",
    "        df[\"StreamAcc\"] = df[\"Top1_Acc_Stream/eval_phase/valid_stream/Task000\"]\n",
    "\n",
    "    df[\"smoothed_StreamAcc\"] = (\n",
    "        df.groupby(\"seed\")[\"StreamAcc\"]\n",
    "        .rolling(10, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    # Check\n",
    "    # print(df[df.seed==0][\"smoothed_StreamAcc\"])\n",
    "    # print(df[df.seed==0][\"StreamAcc\"])\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"mb_index\", y=\"smoothed_StreamAcc\", errorbar=\"sd\", label=method_label, color=colors[i], ax=axes[1]\n",
    "    )\n",
    "    #sns.lineplot(\n",
    "    #    data=df, x=\"mb_index\", y=\"smoothed_StreamAcc\", errorbar=\"sd\", color=colors[i], ax=axes[1]\n",
    "    #)\n",
    "    \n",
    "axes[1].set_xlabel(\"Batch index\")\n",
    "axes[1].set_ylabel(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
