{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "description: How to implement replay and data loading\n",
    "---\n",
    "# Dataloading, Memory Buffers, and Replay\n",
    "\n",
    "Avalanche provides several components that help you to balance data loading and implement rehearsal strategies.\n",
    "\n",
    "**Dataloaders** are used to provide balancing between groups (e.g. tasks/classes/experiences). This is especially useful when you have unbalanced data.\n",
    "\n",
    "**Buffers** are used to store data from the previous experiences. They are dynamic datasets with a fixed maximum size, and they can be updated with new data continuously.\n",
    "\n",
    "Finally, **Replay** strategies implement rehearsal by using Avalanche's plugin system. Most rehearsal strategies use a custom dataloader to balance the buffer with the current experience and a buffer that is updated for each experience.\n",
    "\n",
    "First, let's install Avalanche. You can skip this step if you have installed it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install avalanche-lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataloaders\n",
    "Avalanche dataloaders are simple iterators, located under `avalanche.benchmarks.utils.data_loader`. Their interface is equivalent to pytorch's dataloaders. For example, `GroupBalancedDataLoader` takes a sequence of datasets and iterates over them by providing balanced mini-batches, where the number of samples is split equally among groups. Internally, it instantiate a `DataLoader` for each separate group. More specialized dataloaders exist such as `TaskBalancedDataLoader`.\n",
    "\n",
    "All the dataloaders accept keyword arguments (`**kwargs`) that are passed directly to the dataloaders for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitMNIST\n",
    "from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader\n",
    "benchmark = SplitMNIST(5, return_task_id=True)\n",
    "\n",
    "dl = GroupBalancedDataLoader([exp.dataset for exp in benchmark.train_stream], batch_size=4)\n",
    "for x, y, t in dl:\n",
    "    print(t.tolist())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Memory Buffers\n",
    "Memory buffers store data up to a maximum capacity, and they implement policies to select which data to store and which the to remove when the buffer is full. They are available in the module `avalanche.training.storage_policy`. The base class is the `ExemplarsBuffer`, which implements two methods:\n",
    "- `update(strategy)` - given the strategy's state it updates the buffer (using the data in `strategy.experience.dataset`).\n",
    "- `resize(strategy, new_size)` - updates the maximum size and updates the buffer accordingly.\n",
    "\n",
    "The data can be access using the attribute `buffer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 0\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.storage_policy import ReservoirSamplingBuffer\n",
    "from types import SimpleNamespace\n",
    "\n",
    "benchmark = SplitMNIST(5, return_task_id=False)\n",
    "storage_p = ReservoirSamplingBuffer(max_size=30)\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first, the buffer is empty. We can update it with data from a new experience.\n",
    "\n",
    "Notice that we use a `SimpleNamespace` because we want to use the buffer standalone, without instantiating an Avalanche strategy. Reservoir sampling requires only the `experience` from the strategy's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 30\n",
      "class targets: [9, 9, 9, 9, 5, 9, 5, 9, 9, 5, 5, 9, 9, 5, 9, 9, 5, 5, 9, 5, 5, 5, 9, 9, 5, 9, 9, 9, 9, 5]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [4, 9, 9, 9, 4, 9, 5, 9, 4, 4, 5, 3, 4, 9, 9, 4, 5, 3, 5, 9, 4, 3, 9, 4, 3, 3, 3, 5, 9, 9]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [4, 9, 2, 7, 9, 2, 9, 7, 4, 9, 5, 9, 7, 4, 4, 5, 7, 3, 4, 9, 9, 4, 5, 2, 3, 2, 5, 7, 9, 4]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [4, 9, 2, 7, 9, 2, 0, 9, 7, 4, 9, 5, 9, 7, 1, 4, 4, 5, 7, 1, 3, 4, 9, 1, 9, 4, 5, 2, 3, 2]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [4, 9, 2, 7, 9, 2, 0, 9, 7, 4, 8, 9, 5, 8, 9, 7, 1, 4, 4, 8, 5, 7, 8, 1, 3, 4, 9, 8, 8, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
    "    storage_p.update(strategy_state)\n",
    "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "    print(f\"class targets: {storage_p.buffer.targets}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice after each update some samples are substituted with new data. Reservoir sampling select these samples randomly.\n",
    "\n",
    "Avalanche offers many more storage policies. For example, `ParametricBuffer` is a buffer split into several groups according to the `groupby` parameters (`None`, 'class', 'task', 'experience'), and according to an optional `ExemplarsSelectionStrategy` (random selection is the default choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 0\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 7, 7, 7, 7, 7]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 9, 9, 9, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 7, 7, 7, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 9, 9, 9, 4, 4, 4, 3, 3, 3, 2, 2, 2, 7, 7, 7, 0, 0, 0, 1, 1, 1, 6, 6, 6, 8, 8, 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=30,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    ")\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "for i in range(5):\n",
    "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
    "    storage_p.update(strategy_state)\n",
    "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "    print(f\"class targets: {storage_p.buffer.targets}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The advantage of using grouping buffers is that you get a balanced rehearsal buffer. You can even access the groups separately with the `buffer_groups` attribute. Combined with balanced dataloaders, you can ensure that the mini-batches stay balanced during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(group 5) -> size 3\n",
      "(group 9) -> size 3\n",
      "(group 4) -> size 3\n",
      "(group 3) -> size 3\n",
      "(group 2) -> size 3\n",
      "(group 7) -> size 3\n",
      "(group 0) -> size 3\n",
      "(group 1) -> size 3\n",
      "(group 6) -> size 3\n",
      "(group 8) -> size 3\n"
     ]
    }
   ],
   "source": [
    "for k, v in storage_p.buffer_groups.items():\n",
    "    print(f\"(group {k}) -> size {len(v.buffer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 4, 3, 2, 7, 0, 1, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "datas = [v.buffer for v in storage_p.buffer_groups.values()]\n",
    "dl = GroupBalancedDataLoader(datas)\n",
    "\n",
    "for x, y, t in dl:\n",
    "    print(y.tolist())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Replay Plugins\n",
    "\n",
    "Avalanche's strategy plugins can be used to update the rehearsal buffer and set the dataloader. This allows to easily implement replay strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "from avalanche.training.plugins import StrategyPlugin\n",
    "\n",
    "class CustomReplay(StrategyPlugin):\n",
    "    def __init__(self, storage_policy):\n",
    "        super().__init__()\n",
    "        self.storage_policy = storage_policy\n",
    "\n",
    "    def before_training_exp(self, strategy,\n",
    "                            num_workers: int = 0, shuffle: bool = True,\n",
    "                            **kwargs):\n",
    "        \"\"\" Here we set the dataloader. \"\"\"\n",
    "        if len(self.storage_policy.buffer) == 0:\n",
    "            # first experience. We don't use the buffer, no need to change\n",
    "            # the dataloader.\n",
    "            return\n",
    "\n",
    "        # replay dataloader samples mini-batches from the memory and current\n",
    "        # data separately and combines them together.\n",
    "        print(\"Override the dataloader.\")\n",
    "        strategy.dataloader = ReplayDataLoader(\n",
    "            strategy.adapted_dataset,\n",
    "            self.storage_policy.buffer,\n",
    "            oversample_small_tasks=True,\n",
    "            num_workers=num_workers,\n",
    "            batch_size=strategy.train_mb_size,\n",
    "            shuffle=shuffle)\n",
    "\n",
    "    def after_training_exp(self, strategy: \"BaseStrategy\", **kwargs):\n",
    "        \"\"\" We update the buffer after the experience.\n",
    "            You can use a different callback to update the buffer in a different place\n",
    "        \"\"\"\n",
    "        print(\"Buffer update.\")\n",
    "        self.storage_policy.update(strategy, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And of course, we can use the plugin to train our continual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience  0\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 0 (Task 0) from train stream --\n",
      "100%|██████████| 120/120 [00:03<00:00, 30.37it/s]\n",
      "Epoch 0 ended.\n",
      "Buffer update.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 38.39it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9773\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 36.43it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 33.57it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 33.49it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 33.43it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1939\n",
      "Start of experience  1\n",
      "-- >> Start of training phase << --\n",
      "Override the dataloader.\n",
      "-- Starting training on experience 1 (Task 0) from train stream --\n",
      "100%|██████████| 238/238 [00:08<00:00, 27.59it/s]\n",
      "Epoch 0 ended.\n",
      "Buffer update.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 37.17it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9380\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 38.91it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9878\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 39.34it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 37.91it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 40.96it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3804\n",
      "Start of experience  2\n",
      "-- >> Start of training phase << --\n",
      "Override the dataloader.\n",
      "-- Starting training on experience 2 (Task 0) from train stream --\n",
      "100%|██████████| 226/226 [00:07<00:00, 28.55it/s]\n",
      "Epoch 0 ended.\n",
      "Buffer update.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 39.84it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9037\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 41.32it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8922\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 39.50it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9755\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 36.78it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 34.00it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5376\n",
      "Start of experience  3\n",
      "-- >> Start of training phase << --\n",
      "Override the dataloader.\n",
      "-- Starting training on experience 3 (Task 0) from train stream --\n",
      "100%|██████████| 245/245 [00:08<00:00, 28.35it/s]\n",
      "Epoch 0 ended.\n",
      "Buffer update.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 33.61it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8538\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 33.78it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8785\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 39.18it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9082\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 40.53it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9670\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 41.75it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7116\n",
      "Start of experience  4\n",
      "-- >> Start of training phase << --\n",
      "Override the dataloader.\n",
      "-- Starting training on experience 4 (Task 0) from train stream --\n",
      "100%|██████████| 254/254 [00:09<00:00, 27.93it/s]\n",
      "Epoch 0 ended.\n",
      "Buffer update.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 37.77it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8357\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 40.08it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8871\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 42.04it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9007\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 39.18it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9165\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 34.32it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9929\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9079\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.training import Naive\n",
    "from avalanche.evaluation.metrics import accuracy_metrics\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.models import SimpleMLP\n",
    "import torch\n",
    "\n",
    "scenario = SplitMNIST(5)\n",
    "model = SimpleMLP(num_classes=scenario.n_classes)\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=500,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    ")\n",
    "\n",
    "# choose some metrics and evaluation method\n",
    "interactive_logger = InteractiveLogger()\n",
    "\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(experience=True, stream=True),\n",
    "    loggers=[interactive_logger])\n",
    "\n",
    "# CREATE THE STRATEGY INSTANCE (NAIVE)\n",
    "cl_strategy = Naive(model, torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "                    CrossEntropyLoss(),\n",
    "                    train_mb_size=100, train_epochs=1, eval_mb_size=100,\n",
    "                    plugins=[CustomReplay(storage_p)],\n",
    "                    evaluator=eval_plugin\n",
    "                    )\n",
    "\n",
    "# TRAINING LOOP\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in scenario.train_stream:\n",
    "    print(\"Start of experience \", experience.current_experience)\n",
    "    cl_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    results.append(cl_strategy.eval(scenario.test_stream))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
